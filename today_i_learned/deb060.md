# DEB_060

## Scala WordCount

* 목표: 스칼라를 통해 스파크의 워드카운트 기능을 만든다
  1. 로컬에서 eclipse - scala 환경 구성
  2. ftp를 통해 프로그램 송신
  3. spark 실행

```scala
// 스칼라 버전 확인
scala.util.Properties.versionString
// version 2.12.15
sc
// org.apache.spark.SparkContext (스칼라 프로그램)


val licLines = sc.textFile("/home/hadoop/spark/LICENSE")
// licLines: org.apache.spark.rdd.RDD[String] (RDD[1] 생성)

val lineCnt = licLines.count

val bsdLines = licLines.filter(line => line.contains("BSD"))
// org.apache.spark.rdd.RDD[String] (RDD[2] 생성)

bsdLines.count

def isBSD(line: String) = { line.contains("BSD") } //기본함수
val isBSD = (line: String) => line.contains("BSD")  // 익명함수(람다)
val bsdLines1 = licLines.filter(isBSD)  // 고정함수 RDD[3] 생성
bsdLines1.count
bsdLines.foreach(bLine => println(bLine))
```

* RDD 처리 연산
  * transform 변환 : RDD[n] 생성 (filter, map)
  * action 행동 : 계산결과 반환 (count, foreach)

```scala
--[scala : 실습예제 02 : map 변환 연산자 ] --
//# def map[B](f: (A) ⇒ B): Traversable[B]
//# def map[U](f: (T) => U): RDD[U]

// RDD[4]
val numbers = sc.parallelize(10 to 50 by 10)
numbers.foreach(x => println(x))

// RDD[5]
val numbersSquared = numbers.map(num => num * num)
numbersSquared.foreach(x => println(x))

// RDD[6]
val reversed = numbersSquared.map(x => x.toString.reverse)
reversed.foreach(x => println(x))

// RDD[6]
val alsoReversed = numbersSquared.map(_.toString.reverse)
alsoReversed.foreach(x => println(x))
alsoReversed.first
alsoReversed.top(4)
```

```scala
// --[scala : 실습예제 03 : client-ids.log 파일의 변환] --

echo "15,16,20,20,77,80,94,94,98,16,31,31,15,20" > /home/hadoop/data/client-ids.log

val lines = sc.textFile("/home/hadoop/data/client-ids.log")

val idsStr = lines.map(line => line.split(","))
idsStr.foreach(x => println(x))
idsStr.first
idsStr.collect

// def flatMap[U](f: (T) => TraversableOnce[U]): RDD[U] 이중 array 평면화
val ids = lines.flatMap(_.split(","))
ids.collect
ids.first
ids.collect.mkString("; ")

val intIds = ids.map(_.toInt)
intIds.collect

// def distinct(): RDD[T]
val uniqueIds = intIds.distinct
uniqueIds.collect
val finalCount  = uniqueIds.count		// 고유 카운트
val transactionCount = ids.count		// 카운트
```

```scala
// 샘플링 복원불가
val s = uniqueIds.sample(false, 0.3)
s.count
s.collect

// 샘플링 복원가능
val swr = uniqueIds.sample(true, 0.5)
swr.count
swr.collect

//# def takeSample(withReplacement: Boolean, num: Int, seed: Long = Utils.random.nextLong): Array[T]

val taken = uniqueIds.takeSample(false, 5)
uniqueIds.take(3)
```

```scala
//Implicit conversion: 클래스, 묵시적 형변환 함수 선언
class ClassOne[T](val input: T) { } // 객체 생성
class ClassOneStr(val one: ClassOne[String]) {
    def duplicatedString() = one.input + one.input
}
class ClassOneInt(val one: ClassOne[Int]) {
    def duplicatedInt() = one.input.toString + one.input.toString
}

implicit def toStrMethods(one: ClassOne[String]) = new ClassOneStr(one)
implicit def toIntMethods(one: ClassOne[Int]) = new ClassOneInt(one)

val oneStrTest = new ClassOne("test")
val oneIntTest = new ClassOne(123)
oneStrTest.duplicatedString()
oneIntTest.duplicatedInt()
```

```scala
// double RDD 함수를 통한 기초통계량
intIds.mean
intIds.sum

intIds.variance
intIds.stdev

// 히스토그램 histogram --> hist

intIds.histogram(Array(1.0, 50.0, 100.0))
intIds.histogram(3)
```

### 파일읽기

```scala
// txt 파일 읽기
val tranFile = sc.textFile("/home/hadoop/data/data_transactions.txt")
// split 처리
val tranData = tranFile.map(_.split("#"))
var transByCust = tranData.map(tran => (tran(2).toInt, tran))
transByCust.foreach(x => print(x))
transByCust.keys.distinct().count()

transByCust.countByKey() // group by key count
transByCust.countByKey().values.sum
```

---

- HelloWorldObject 테스트
- [참조] https://www.scala-lang.org/download/2.12.10.html

```shell
wget https://downloads.lightbend.com/scala/2.12.10/scala-2.12.10.tgz

tar -xvzf scala-2.12.10.tgz

cp -r scala-2.12.10 ../scala-2.12.10

vi .bashrc
##############################
export SCALA_HOME=/home/hadoop/scala-2.12.10
export PATH=$PATH:~~~~~~:$SCALA_HOME/bin
##############################

cat > HelloWorldObject.scala
##############################
	// main 함수를 생성App 을 상속하여 실행하는 방법 
	object HelloWorldObject {
  	def main(args: Array[String]): Unit = {
    	println("Hello World main")
  	}
	}
##############################
scalac HelloWorldObject.scala
scala HelloWorldObject
```

```scala
val (cid, purch) = transByCust.countByKey().toSeq.sortBy(_._2).last
var complTrans = Array(Array("2015-03-30", "11:59 PM", "53", "4", "1", "0.00"))

// 구매횟수가 가장 많았던 고객의 ID 와 구매숫자
val (cid, purch) = transByCust.countByKey().toSeq.sortBy(_._2).last

transByCust.lookup(53)
transByCust.lookup(53).foreach(tran => println(tran.mkString(", ")))



transByCust = transByCust.mapValues(tran => {
     if(tran(3).toInt == 25 && tran(4).toDouble > 1)
         tran(5) = (tran(5).toDouble * 0.95).toString
     tran })



transByCust = transByCust.flatMapValues(tran => {
    if(tran(3).toInt == 81 && tran(4).toInt >= 5) {
       val cloned = tran.clone()
       cloned(5) = "0.00"; cloned(3) = "70"; cloned(4) = "1";
       List(tran, cloned)
    }
    else
       List(tran)
    })



transByCust = transByCust.mapValues(tran => {
     if(tran(3).toInt == 25 && tran(4).toDouble > 1)
         tran(5) = (tran(5).toDouble * 0.95).toString
     tran })

transByCust = transByCust.flatMapValues(tran => {
    if(tran(3).toInt == 81 && tran(4).toInt >= 5) {
       val cloned = tran.clone()
       cloned(5) = "0.00"; cloned(3) = "70"; cloned(4) = "1";
       List(tran, cloned)
    }
    else
       List(tran)
    })

val amounts = transByCust.mapValues(t => t(5).toDouble)
val totals = amounts.foldByKey(0)((p1, p2) => p1 + p2).collect()
totals.toSeq.sortBy(_._2).last
amounts.foldByKey(100000)((p1, p2) => p1 + p2).collect()


complTrans = complTrans :+ Array("2015-03-30", "11:59 PM", "76", "63", "1", "0.00")

transByCust = transByCust.union(sc.parallelize(complTrans).map(t => (t(2).toInt, t)))
transByCust.map(t => t._2.mkString("#")).saveAsTextFile("output-transByCust")

val prods = transByCust.aggregateByKey(List[String]())(
   (prods, tran) => prods ::: List(tran(3)),
   (prods1, prods2) => prods1 ::: prods2)
prods.collect()
```

* spark rdd 파티션 나누기

  : 참조 https://ichi.pro/ko/apache-sparkui-patisyeon-su-gyeoljeong-1-bu-248603929832148

